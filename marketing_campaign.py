# -*- coding: utf-8 -*-
"""marketing_campaign.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u58DeZzQ2zdw6q9c3fxNITUneU9zeGbD
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import seaborn as sns
from sklearn.preprocessing import StandardScaler, normalize
import plotly.graph_objects as go
from sklearn import metrics
import warnings
warnings.filterwarnings("ignore")
from sklearn.mixture import GaussianMixture

"""import numpy as np
import pandas as pd
import datetime
from datetime import date
import matplotlib
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from sklearn.preprocessing import StandardScaler, normalize
from sklearn import metrics
from sklearn.mixture import GaussianMixture
from mlxtend.frequent_patterns import apriori
from mlxtend.frequent_patterns import association_rules
import warnings
warnings.filterwarnings('ignore')
data=pd.read_csv('marketing_campaign.csv',sep=';',header=0)
"""

data=pd.read_csv("/content/marketing_campaign.csv",sep=";",header=0)

data.head()

data.shape

"""In our dataset we have 2240 rows and 29 columns."""

data.describe()

"""Finding Null values in dataset"""

data.info()

data.isnull()

"""Finding Sum of null values in each columns. Here we find that only in Income column we have 24 null values."""

data.isnull().sum()

"""Finding Duplicate values

"""

data.duplicated()

data.duplicated().sum()

"""# Data Cleaning

Formate Date to Datetime
"""

data['Dt_Customer']=pd.to_datetime(data['Dt_Customer'])
data.columns=data.columns.str.lower()

data.head(3)

"""Fill in null values

Finding percentage of missing values in dataset.
Here we find that only 1.07% of income data is missing.
"""



missing_data_percentage=data.isnull().sum()*100/len(data)
missing_data_percentage

data['income'].bfill

data['income'].bfill(inplace=True)
data['income'].bfill

data.isnull().sum()

"""Feature creating.

"""

data['age']=np.subtract(2023,data['year_birth'])
data['age']

data.columns

print(data.shape)

"""Visit"""

data['visit'] =data['recency'].apply(lambda x : 'Regular' if (x>=0 and x<=31 ) else 'Not Regular')
data['visit']

"""Income Level"""

data['income_level']=data['income'].apply(
    lambda x : 'Low_Income' if (x<=50000)
    else 'Medium_Income' if (x>=50000 and x<=150000)
    else 'High')

data['income_level']

print(data.columns)
print(data.shape)

data['Total_Children']=np.add(data['kidhome'],data['teenhome'])
data['Total_Children']

"""Total Purchase"""

data['Total_Purchase']=data['mntfruits']+data['mntwines']+data['mntmeatproducts']+data['mntfishproducts']+data['mntsweetproducts']+data['mntgoldprods']
data['Total_Purchase']

data.iloc[:5]

"""# EDA- Exploratory Data Analysis

Mean
"""

round(data[['age','income','Total_Children']].mean())

"""Trimmed mean"""

from scipy.stats import trim_mean
cols=['age','income','Total_Children']

for index in cols:
  print(f"{index} : {trim_mean(data[index].sort_values(ascending=False),0.1):,.0f}")

"""Weighted Mean"""

for index in cols:
  print(f"{index} : {np.average(data[index],weights=data['recency']):,.0f}")

"""Median"""

data[['age','income','Total_Children']].median()

"""Weighted Median"""

!pip install wquantiles
import wquantiles as wq
for index in cols:
  print(f"{index} : {wq.median(data[index],weights=data['recency']):,.0f}")

"""Estimated variability

Variance
"""

round(data[['age','income','Total_Children']].var())

"""Standard deviation"""

round(data[['age','income','Total_Children']].std())

"""Mean Absolute Deviation"""

for index in cols :
  print(f"{index} : {np.mean(np.absolute(data[index]-data[index].mean())):,.0f}")



"""Median Absolute deviation"""

for index in cols :
  print(f"{index} : {np.median(np.absolute(data[index]-data[index].median())):,.0f}")

"""Inter Quartile Range"""

for index in cols:
  iqr1,iqr2=np.percentile(data[index],[75,25])

print(iqr1)
print(iqr2)
print(f"{index} : {np.subtract(iqr1,iqr2)}")

"""#EDA-- Exploratory Data Analysis

Boxplot
"""

plt.figure(figsize=(16,6))
plt.subplot(1,2,1)
data.boxplot(column=["age"])
plt.subplot(1,2,2)
data.boxplot(column=["Total_Children"])
plt.show()

plt.figure(figsize=(16,6))
data.boxplot(column=['income'])
plt.show()

"""Percentile"""

data[['age','income','Total_Children']].quantile([0.05,0.25,0.5,0.70,1])

print(data[['age','income','Total_Children']].quantile([0.05,0.25,0.5,0.70,1]))

"""Histogram & KDE

Age
"""

plt.figure(figsize=(15,5))
sns.histplot(x=data['age'],kde=True,bins=25)
plt.xlabel("Birth Year")
plt.ylabel("Frequency")
plt.show()

plt.figure(figsize=(15,5))
sample_amounts=range(10,150,20)
for index in sample_amounts:
  samples= []
  for i in range(1000):
    samples.append(data['age'].sample(index).mean())
  plt.hist(samples)
plt.legend([str(z)+'samples' for z in sample_amounts])
plt.title("Central lilmit theorem")
plt.show()

import scipy.stats as st
fig,ax=plt.subplots(figsize=(15,5))
norm_sample=data['age'].sample(649)
st.probplot(norm_sample,plot=ax)
plt.show()

"""Income"""

plt.figure(figsize=(15,5))
sns.histplot(x=data['income'],kde=True,bins=35)
plt.xlabel('Income')
plt.ylabel('Frequency')
plt.show()

"""Income is Right skewed"""

plt.figure(figsize=(15,5))
plt.sample_amounts=range(10,200,20)
for index in sample_amounts :
  samples= []
  for i in range(10000):
    samples.append(data['income'].sample(index).mean())
  plt.hist(samples)
plt.legend([str(z)+'samples' for z in sample_amounts])
plt.title("Central lilmit theorem : Income")
plt.show()

plt,ax=plt.subplots(figsize=(15,5))
norm_sample=data['income'].sample(599)
st.probplot(norm_sample,plot=ax)
plt.show()

sns.histplot(x=data['recency'],kde=True,bins=10)
plt.title("Recency")
plt.show()

import matplotlib.pyplot as plt
plt.figure(figsize=(16,6))
sns.histplot(x=data['recency'],bins=10,kde=True)
plt.title('Recency')
plt.show()

fig,ax=plt.subplots(figsize=(15,5))
norm_sample=data['recency'].sample(499)
st.probplot(norm_sample,plot=ax)
plt.show()

"""Explain two or more variable"""

ax=(data['education'].value_counts(normalize=True)*100).sort_values().plot(kind='barh',figsize=(16,6),title='Education Status')
for a in ax.containers:
    plt.bar_label(a,fmt='%.2f%%')
plt.show()

"""50% Customers as graduates"""

ax=(data['marital_status'].value_counts(normalize=True)*100).sort_values().plot(kind='barh',figsize=(16,4),title='Martial_status')
for a in ax.containers:
  plt.bar_label(a)
plt.show()

"""Almost 38% of population is married,while Yolo & Absurd consist of 0.18% of population."""

ax=(data['Total_Children'].value_counts(normalize=True)*100).sort_values().plot(kind='barh',figsize=(16,4),title="Total No. Of Children")
for a in ax.containers:
  plt.bar_label(a)

plt.show()

"""Almost 50% of population have 1 children. Approx 28.5% of population have No children while 2.3% population have 3 children."""

ax=(data['visit'].value_counts(normalize=True)*100).sort_values().plot(kind='barh',figsize=(16,4),title="Recency")
 for a in ax.containers:
  plt.bar_label(a)

plt.show()



ax=(data['visit'].value_counts(normalize=True)*100).sort_values().plot(kind='barh',figsize=(16,4),title="Recency")
for a in ax.containers:
  plt.bar_label(a)

plt.show()

"""Almost 67% of total customers are not regular"""

ax=(data['income_level'].value_counts(normalize=True)*100).sort_values().plot(kind='barh',figsize=(16,4),title="Income_Level")
for a in ax.containers:
  plt.bar_label(a,fmt='%2f%%')
plt.show()

"""Only 0.36% of population comes under High income velev family, which is less then 0.5% of total population. 51.6% of population is medium income level family."""

plt.figure(figsize=(16,4))
ax=sns.barplot(
    x=(data.groupby('Total_Children')['education'].value_counts(normalize=True)*100).index.get_level_values(0),
    y=(data.groupby('Total_Children')['education'].value_counts(normalize=True)*100).values,
    hue=(data.groupby('Total_Children')['education'].value_counts(normalize=True)*100).index.get_level_values(0)
    )
for a in ax.containers:
  plt.bar_label(a,fmt="%2f%%")
plt.title("Total no of children by Education")
plt.legend(loc=[0.9,0.8])
plt.show()

plt.figure(figsize=(16,4))
ax=sns.barplot(
    x=(data.groupby('Total_Children')['education'].value_counts(normalize=True)*100).index.get_level_values(0),
    y=(data.groupby('Total_Children')['education'].value_counts(normalize=True)*100).values,
    hue=(data.groupby('Total_Children')['education'].value_counts(normalize=True)*100).index.get_level_values(1)
    )
for a in ax.containers:
  plt.bar_label(a,fmt="%2f%%")
plt.title("Total no of children by Education")
plt.legend(loc=[0.9,0.8])
plt.show()

"""As per analyzing graph Graduates are widely distributed as compared to basic education."""

plt.figure(figsize=(16,4))
ax=sns.barplot(
    x=(data.groupby('Total_Children')['marital_status'].value_counts(normalize=True)*100).index.get_level_values(0),
    y=(data.groupby('Total_Children')['marital_status'].value_counts(normalize=True)*100).values,
    hue=(data.groupby('Total_Children')['marital_status'].value_counts(normalize=True)*100).index.get_level_values(0)
    )
for a in ax.containers:
  plt.bar_label(a,fmt="%2f%%")
plt.title("Total no of children by marital_status")
plt.legend(loc=[0.9,0.8])
plt.show()

plt.figure(figsize=(16,4))
ax=sns.barplot(
    x=(data.groupby('Total_Children')['marital_status'].value_counts(normalize=True)*100).index.get_level_values(0),
    y=(data.groupby('Total_Children')['marital_status'].value_counts(normalize=True)*100).values,
    hue=(data.groupby('Total_Children')['marital_status'].value_counts(normalize=True)*100).index.get_level_values(1)
    )
for a in ax.containers:
  plt.bar_label(a,fmt="%2f%%")
plt.title("Total no of children by marital_status")
plt.legend(loc=[0.9,0.8])
plt.show()

"""Married couples are greatly dispersed compared to YOLO and Absurd people."""

plt.figure(figsize=(16,4))
ax=sns.barplot(
    x=(data.groupby('marital_status')['visit'].value_counts(normalize=True)*100).index.get_level_values(0),
    y=(data.groupby('marital_status')['visit'].value_counts(normalize=True)*100).values,
    hue=(data.groupby('marital_status')['visit'].value_counts(normalize=True)*100).index.get_level_values(0)
    )
for a in ax.containers:
  plt.bar_label(a,fmt="%2f%%")
plt.title("marital_status by recency")
plt.legend(loc=[0.9,0.8])
plt.show()

plt.figure(figsize=(16,4))
ax=sns.barplot(
    x=(data.groupby('marital_status')['visit'].value_counts(normalize=True)*100).index.get_level_values(0),
    y=(data.groupby('marital_status')['visit'].value_counts(normalize=True)*100).values,
    hue=(data.groupby('marital_status')['visit'].value_counts(normalize=True)*100).index.get_level_values(1)
    )
for a in ax.containers:
  plt.bar_label(a,fmt="%2f%%")
plt.title("marital_status by recency")
plt.legend(loc=[0.9,0.8])
plt.show()

"""All yolo couples are regular customers where as Absurd couples are not regular customers"""

plt.figure(figsize=(16,4))
ax=sns.barplot(
    x=(data.groupby('marital_status')['income_level'].value_counts(normalize=True)*100).index.get_level_values(0),
    y=(data.groupby('marital_status')['income_level'].value_counts(normalize=True)*100).values,
    hue=(data.groupby('marital_status')['income_level'].value_counts(normalize=True)*100).index.get_level_values(0)
    )
for a in ax.containers:
  plt.bar_label(a,fmt="%2f%%")
plt.title("marital_status by Income_level")
plt.legend(loc=[0.9,1.0])
plt.show()

plt.figure(figsize=(16,4))
ax=sns.barplot(
    x=(data.groupby('marital_status')['income_level'].value_counts(normalize=True)*100).index.get_level_values(0),
    y=(data.groupby('marital_status')['income_level'].value_counts(normalize=True)*100).values,
    hue=(data.groupby('marital_status')['income_level'].value_counts(normalize=True)*100).index.get_level_values(1)
    )
for a in ax.containers:
  plt.bar_label(a,fmt="%2f%%")
plt.title("marital_status by Income_level")
plt.legend(loc=[0.9,1.0])
plt.show()

"""Yolo couples are low income. Absurd couples as medium income. And Married, Divorced and together couples approx 1.45% of high income.

Correlation

Correlation Matrix
"""

data[['age','income','Total_Children']].corr()

plt.figure(figsize=(16,6))
sns.heatmap(data[['age','income','Total_Children']].corr(),annot=True)
plt.show()

"""Low correlation between :
1. Age and income
2. Income and Total_children

"""

data.corr()

plt.figure(figsize=(16,4))
sns.scatterplot(x=data['age'],y=data['income'],hue=data['income_level'])
plt.title("Age by Income")
plt.show()

plt.figure(figsize=(16,4))
sns.regplot(x=data['age'],y=data['income'])
plt.title("Age by Income")
plt.show()

"""Low positive correlation between age and income.

Chisquare test of association:
---
.) Null Hypothesis : There is no association between age and income

---
.)Alternet Hypothesis : There is an association between age and income
"""

import scipy.stats

from scipy.stats import chi2_contingency
result=st.chi2_contingency(data[['age','income']])
print(f"Statistics : {result.statistic}\nP-Value : {result.pvalue}\nDegree of Freedom : {result.dof}")

"""Using Significant level of 5% we reject Null hypothesis in favour of Alternet hypothesis.

Exploring Binary and contingency data

Contigency Table
"""

contigency_table=pd.pivot_table(data=data,index='age',columns=['Total_Children'],values='income',fill_value='No Record',aggfunc=['mean'])

contigency_table.iloc[1:11]

"""Boxplot"""

plt.figure(figsize=(16,10))
plt.subplot(3,2,1)
sns.boxplot(x=data['mntwines'],hue=data['income_level'])
plt.subplot(3,2,2)
sns.boxplot(x=data['mntfruits'],hue=data['income_level'])
plt.subplot(3,2,3)
sns.boxplot(x=data['mntmeatproducts'],hue=data['income_level'])
plt.subplot(3,2,4)
sns.boxplot(x=data['mntfishproducts'],hue=data['income_level'])
plt.subplot(3,2,5)
sns.boxplot(x=data['mntsweetproducts'],hue=data['income_level'])
plt.subplot(3,2,6)
sns.boxplot(x=data['mntgoldprods'],hue=data['income_level'])
plt.show()

"""Outlier Detection and Removal using InterQuartile Range

Age

Find Interquartile range
"""

iqr1,iqr2=np.percentile(data['age'],[75,25])
IQR=np.subtract(iqr1,iqr2)
IQR

"""Find Upper and Lower Limit"""

Upper_limit=iqr1+1.5*(IQR)
Lower_limit=iqr2-1.5*(IQR)
print(f"Upper_limit: {Upper_limit}\n Lower_limit : {Lower_limit}")

"""Remove outlier in age"""

data.columns

"""MOdel Development

Choose Relevant Features
"""

X=data[['income','Total_Purchase']]

"""Perform Elbow method"""

from sklearn.cluster import KMeans

wcss=[]
for index in range(1,11):
    kmeans=KMeans(n_clusters=index,init='k-means++')
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)

plt.figure(figsize=(16,6))
plt.plot(range(1,11),wcss,linewidth=2,marker='8')
plt.title('Elbow Method')
plt.xlabel('No of Clusters')
plt.ylabel('WCSS Values')
plt.show()

""" Build & Fit Model"""

model=KMeans(n_clusters=3,init='k-means++')
y_pred=model.fit_predict(X)

print(f'Cluster Centers\n{model.cluster_centers_}')

plt.figure(figsize=(16,6))
plt.scatter(X['income'],X['Total_Purchase'],s=100,c=model.labels_,cmap='rainbow')
plt.scatter(model.cluster_centers_[:,0],model.cluster_centers_[:,1],s=100,color='black')
plt.title('Clusters of Customers')
plt.xlabel('Income')
plt.ylabel('Total Purchase')
plt.show()

